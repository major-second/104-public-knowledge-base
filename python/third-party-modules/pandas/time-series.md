- 前置
  - [[pandas/installation]]
  - [[matplotlib/basics]]
  - [[series-dataframe]]
## 基础
### 准备
- [参考](https://www.dataquest.io/blog/tutorial-time-series-analysis-with-pandas/)
- shell中`wget https://raw.githubusercontent.com/jenfly/opsd/master/opsd_germany_daily.csv`即可下载数据（需要[[linux-proxy-client]]代理）
- `import pandas as pd`
- 日期时间参考[[timestamps]]
### 基础命令
- `opsd_daily = pd.read_csv('opsd_germany_daily.csv')`
  - 这是读取`.csv`，参考[[series-dataframe]]
- `df.shape`形状（第0维往往表示多少条数据，第1维表示多少维）
- `df.dtypes`类型
- `df.head(3)`, `df.tail(3)`, `df.sample(3)`看示例
- `pd.concat(<DataFrame组成的表，元组等>)`：参考[[manipulation]]，有点像，在时间维上拼起来
- `.min(), .max(), .mean(), .std(), .quantile(q=[0.25,0.75)`等常见操作
### `index`
- 一行是一个数据条目，一列是一种属性（feature）
  - 默认先说属性再说时间范围（数据条目）
  - 少部分例外，例如可以`data[0:1]`取出（时间范围）切片
    - 注：若index是时间，则`data[0:1]`取出的是第0条，但若index是数，则`data[0:1]`取出index在该范围内的，而不是“第几条”
    - [[finetune]]中的例子其实就可以使用`[low: high]`取范围内的，只不过我没用
  - 但`data[0]`可不行，因为此时会把`0`解释为属性名
- 有了日期时间，即可利用pandas自动读日期时间的功能，设置index
  - 如果日期字段名是`Date`，则`opsd_daily = opsd_daily.set_index('Date')`
  - 此时可再看`.shape, .dtypes, .sample(3)`的变化
- `.index`取出index序列
  - 参考[[series-dataframe]]中的`index`，知道默认值是`0`开始的整数列
  - 还能`.index.start`等取出具体值
  - `df.index = df[key]`还能设置哪一列是index
    - `.sort_index()`返回按索引排序的结果（但`DataFrame`自己不[[inplace]]改变）
    - 这里返回的结果默认是“按某列排序，但将排序结果扩展到其它列”，而不是只排某一列其它不变
- 直接设置`index`：`.set_index(<index>, inplace=True)`
  - 参考[[inplace]]
  - 不[[inplace]]就是`df_new = df.set_index(...)`
- 二合一过程（读取和设置`index`）
  - `opsd_daily = pd.read_csv('opsd_germany_daily.csv', index_col=0, parse_dates=True)`
  - `0`号栏此时对应`Date`
- `values`取出具体数值
  - 是[[numpy/basics]]的数组，于是可进行`numpy`的索引等操作，参考[[numpy/basics]]
- 增加列：`data[key] = value`或`data.loc[:, key] = value`
  - 可以是赋予单个数，也可以是序列
  - value是`Series`时，要注意有没有让他的`index`和你的`data`的`index`一致
  - 注意pandas官方的一个tricky bug，参考[[leaky-abstraction]]
- 取出多个键作为“子”数据集：`df[[key0, key1]]`
  - 例如做两个变量间的[[regression]]时，只需要[[dropna]]涉及他俩的`NaN`，而不需要全部drop，就需要此“子”数据集
  - 也可以用[[ordered-dict]]思想，即`df[df.columns[...]]`
### `.loc`
- 有了index，此时可以用`.loc['2014-01-20']`，乃至`.loc['2014-01-20':'2014-01-22']`，`.loc['2006-12']`等和时间相关的feature
  - 切片第三个分量：比如`1, -1, -4`这种都行，表示“间隔条目数”，所以和第一第二个的“数据类型”未必相同
- `df.loc[0, 'key'] = value`这样比`df['key'][0] = value`好（后者会报[[warning]]，和[[general-principles/copy]]有关）
  - 但注意如果`index`不是数字（`0`）之类的，就不行。必须用`df.index`取出，例如`df.loc[df.index[0], 'key']`
  - 而且此时千万不能漏了`.loc`写成了`df[0, 'key']`，否则变成了`0`和`'key'`两个column
- loc很多坑，[参考文档](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html?highlight=loc#pandas.DataFrame.loc)
  - 和普通的`[]`不同，`.loc[]`**切片含两端**
  - 普通的`[]`只能取`[start:end]`这样，不能单取一个`[0]`这样，但`.loc`可以
  - `.loc`默认是“绝对”的索引，而不是相对
    - `.loc[0]`中的0是某个数据条目的一个属性（`index`），相当于某种特殊feature，而不是其在某个序列中的排序
    - 也就是“二次”切片时不能“相对”切。例如`d.loc[3:4]`的结果就不能再`.loc[0]`了！
    - 所以`.loc`似乎天然适合用于处理关于日期时间的索引切片
  - `.loc[单个]`和`.loc[start:end]`出来的数据类型不一样（这点不同于python原生字符串切片）
    - 所以对两种出来结果再切片时效果也当然不同
## 迭代
- 直接`for k in df`得到的是键的列表，类似于迭代字典
- 如果`for k in df.iterrows()`可以按行迭代
  - 但如果你（经常）用这个，不妨先看看怎么[[parallelism]]并行，要不然你pandas约等于白学233
- `for k in series`当然是按顺序一个一个来，这点可以看出有1个字段的`DataFrame`和`Series`不同
## 进阶
- [一个参考](https://blog.csdn.net/weixin_42033491/article/details/108104305)
- `groupby`和`shift`，`diff`
  - 首先把`df`分成互相间没关系的若干组，有一列`name`表示
  - 然后例如`df['value_shift'] = df.groupby('name')['value'].shift(1)`，就新增一列，每一个“组”之内进行平移
  - 默认省略参数`1`
  - `diff`作差同理
    - 注：所以如果要未来减现在，那就`-df['key'].diff(-interval)`
- `groupby`和`mean`
  - 比如典型操作：`new_df['x']`是旧的`df['x'].rank(pct=True) * 10 // 1`，即0到9整数，`'y'`也同理
  - 然后`new_df.groupby(['x','y']).mean()`即可获得有二维`index`，针对每个`x,y`组合的均值
- 之前说过排序用`sort_index()`，那想获取序号作为数据怎么办？
  - 可以`data['sorted'] = data['key'].rank(ascending=False, method='first')`
  - 其中`ascending`（布尔）决定排序方向，`method`表示相同的怎么处理，`pct`表示是否以“相对”值展现（在机器学习中要是作为特征，则特别实用）