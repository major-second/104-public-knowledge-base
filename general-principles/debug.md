- 在正式运行前，往往需要先调试确认没有问题。调试时往往
  - 使用较少资源（gpu、cpu等）和待测试数据，降低成本，加快调试迭代速率
  - 使用较简单的模式
    - 比如要用单线程，而不用distributed data parallel, ddp等
      - 多线程时，打一个[[breakpoint]]会被断多次，使得调试过程不够清晰
      - 报错也会更模糊，例如[[make]]中的`-j8`会导致报错被“埋起来”
    - 比如调试某个函数本身时，先不用[[cache-decorator]]，否则[[jupyter-notebook/basics]]中进不去函数
  - 在小规模到大规模前，可能可以加入“中规模”，并多print东西，方便看到性能瓶颈所在（有一次在`matplotlib`中，[[scatter]]了几百万个点导致慢，233）
- 可以分成多段，逐段调试
  - 例如[[jupyter-notebook/basics]]的原生在线用法不支持断点，所以要多分几段
- 在跑一个大实验之前，下载大东西等等之前要做的调试
  - 确认小规模全流程没问题
    - 流程问题
      - 存文件，存checkpoint，validation等等
      - 可能不是一来就跑到这个地方，而是跑了一会才跑到这个地方
      - 你要是一开始没有测试就开很大的实验，那么可能跑了很久到这里才报错停下，那就损失大了
      - 例如`pytorch_lightning`中的`sanity_check`就是默认在训练前先尝试`val`一下
    - 本质上错误
      - 比如[[hand-eye-calibration]]中可以先跑少数几个点看结果靠不靠谱，排除选错坐标系等情况
  - 确认断点、调试用的脚手架等都被去除了！要不然跑了一晚上，早上起来发现卡在断点，尴尬
  - 确认有没有[[silent]]（比如可能需要`y`确认，你没按，它一直等着，你晕不晕吧）
  - 确认磁盘空间够不够，参考[[resource-management/commands]]
    - 参考下一节，我们经常有code和data分开的思想。常常把data链接到code文件夹下
    - 那么code文件夹下做数据预处理时，要小心存放目录不要在code的那个盘
    - 常见模式
      - code是`/home`，data是`/DATA/disk1`（外接的TB级的硬盘）
      - code是`/`，data是`/home`（参考[[partition]]）
  - 确认有没有僵尸进程没`kill`掉，参考[[4-more-commands]]
    - 否则明明本来资源够的，也可能不够（如显存、内存等）
  - 有自己独占的就不要用和别人共用的。万一[[isolation]]没做好，对面来个新手把服务器搞崩了，就好玩了
## 一条原则：“代码和数据”
- 出bug除了代码出问题，也可能数据出问题！
- 如：不同code（通常是不同版本的code）生成的数据（遵守不同contract的数据）
  - 最难debug的是缺乏类型检查（python，还不用typing的那种），并且意义不同的值具有相同类型的数据
  - 也就是表面上遵守相同contract，但实际不是
  - 参考[[exception-warning]]
- 有随机性的code生成几次数据，没有“对应着”使用
  - 在需要连续作很多步处理的场景中，如果你第一步用这个种子对应的数据，第二步用那个种子对应的数据，就可能有麻烦
- 数据中有个别脏的
  - 例如[[nan]]
  - [[seaborn]]中有一个`.dropna()`例子
  - 例如有个别损毁（少个key啥的），你不过滤一下，就导致整个没法用……
## 调试时间、资源消耗（profiling）
- 参考[[resource-management/commands]]实时消耗情况
- 如何查看时间消耗
  - 包内置的工具如[[profile]]
  - 通用方法，如`from time import time; t = time(); <others>; print(time() - t)`
  - [[comment]]系统的一部分对照试验
  - [[third-party-modules/tqdm]]，[[jupyter-notebook/tqdm]]包在此过程中实用