损失和$\theta$（参数）和$a$（行动，比如[[2-estimation]]一个参数估计值）有关
比如
- [[2-estimation]]的误差（绝对值或平方）就可以是“损失”，这样导出贝叶斯估计
- [[3-hypothesis]]中，选择错误的分类也可以指定损失（甚至可以错得越离谱损失越大这样），这样导出贝叶斯检验

估计里面经常需要一致（比如[[优良标准]]），然而现在损失很难（对参数）一致最小，那
- 可以保守（minimax）
- 可以引入“期望”，就要认为$\theta$有（先验）概率分布（[[bayes]]出现）
  - 这时的估计问题：观测数据把先验变成后验。在后验分布上损失函数期望应当最小
- 先验怎么选？往往是好算（代数上的封闭性），参考[[conjugate]]