# 经验误差与过拟合
- 二分类：错误率、精度
- 误差、训练误差（经验误差）、泛化误差
- 过拟合：把训练样本中的特点当成了所有潜在样本都有的性质，导致测试性能下降
  - 如：学习能力太强（这个强和模型、数据都有关）
  - 哲学上：P不等于NP，过拟合就不可避免，否则通过[[化归]]就$P=NP$了
- 模型选择：如何让泛化误差小？
  - 当然：现实中还有时空复杂性、可解释性等
# 评估方法
- 测试集、i.i.d于训练集，不能在训练过程中使用过
- 留出：直接划分成两个互斥集合
  - 如（针对样本比例）分层采样
  - 多次这样留出可以得到多个评估结果，还能算分布等
  - 典型：用留出先找到好的参数，然后用整个集合再训
- 一个实际问题：对于一年内的数据
  - 留出最后若干天：最保险，无leakage风险
  - 但缺点：训练和测试有gap，导致验证效果不准确
- 留出的[[tradeoff]]
  - 如果训练集S太大，评估不稳定准确
  - 如果S太小，则保真性fidelity不强（不能反映全集D上模型的性能）
  - [[偏差-方差分解]]角度：S小评估结果方差大，否则偏差大
  - 一般而言，测试集至少30个样例，常见做法使用1/5到1/3
- 交叉验证：$k$折（常见10），均分$k$份，每次用$k-1$训，1验证
  - 也可以多次随机分，如“10次10折”共100次
  - 极端：留一。好处：偏差小（且如果训非常非常多模型也可以使方差小）
- 自助（bootstrap）
  - 词源
    - 解靴带自助，“自己提自己上天”
    - 参考[[bootstrap]]
    - 和系统启动boot（如[[u-disk-boot]], [[multiple-ubuntu-versions]]）是一个词
    - [[bootstrap]]那里乃至系统boot强调的是在有限条件下自己逐步搞定步骤
    - 这里强调的是不需要人为划分，而是通过$(1-1/m)^m\to 1/e$自己进行划分，得到和$D$大小相同的数据集$S$
      - 注：这是重要极限[[calculus/limit]]的应用
    - 同一个词，侧重点不同，但都体现“自己做”意思
  - 数据集小好用。数据集大时没必要（改变分布了）
- 调参：如设网格
  - 有指数爆炸问题，如3个参数，每个参数5档，就125种了
  - 可以认为调参和选择算法没有本质区别（例如：“网络层数”？）
# 性能度量
- 这就相当于[[utility-function]]，决定了我们最终[[tradeoff]]到底是为了什么
- “什么模型好”：考虑算法、数据、任务需求
- 回归：均方误差，$(f(x)-y)^2$的[[expectation]]
  - 可以写成$\frac 1m \sum_{i=1}^m (f(x_i)-y_i)^2$或者$\int_{x\sim \mathcal D} (f(x)-y)^2p(x)dx$
- 分类
  - 基础：错误率、精度
    - 对imbalanced问题，显然“精度”不是个好指标。你全都分到一种就行
- 对二分类问题，有“正”“负”，地位不对等，能考察更精细的度量
  - precision（查准率、准确率）
    - 所有正例中有多少是真的
      - 即：预测正的集合中，是否错误包含了很多实际上负的
    - 极端情况100%
      - 对应逻辑中[[可靠性]]（我说是正例，就是正例，类比：我说是定理，就是定理）
      - 若“正例”对应“否定假设”，则对应[[水平和功效]]中水平为0（然而并不能直接类比，参考[[水平和功效]]）
    - 所以GT中如果1太少（不均衡），可能准确率就一直很低
      - 均衡数据才适宜于这个
  - recall（查全率、召回率）
    - 所有真的中有多少是正例
      - 即：实际上正的集合中多少能被检测出来
    - 直接对应[[水平和功效]]的功效
    - 极端情况100%
      - 对应逻辑中[[完全性]]（你客观上有定理/正例，我一定能找到）
  - 两者间存在[[tradeoff]]，所以可以根据二分类判断的“概率”，画出[[pareto-efficient]]的前沿，作为P-R曲线
    - 利用曲线比较优劣：如果完全包住当然没疑问，否则可能需要手造[[utility-function]]
    - 如面积、两者相等时值、调和平均$F_1$、加权调和平均$F_\beta$
  - 对多次实验，多组$TP,TN,FP,FN$矩阵值：先运算得到$P,R,F_1$再做平均，还是先做平均再运算？有宏、微之分
- todo