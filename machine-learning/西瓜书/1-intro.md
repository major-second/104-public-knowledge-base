- 学习的形式化定义：利用经验E提升在任务类T上关于评价标准P的性能
# 引言、基本术语
- “模型”：学习到的结果（例如一棵决策树）
  - 有些资料：模型是全局，模式是局部
- 常见术语：dataset, instance, sample, attribute, feature, attribute value, attribute space (sample space), feature vector
  - 在样本空间中采样。上下文判断“样本”指的是一个数据点还是整个数据集
- 约定记号：$\{x_1,\cdots,x_m\}$为$m$个样本，其中$x_i = (x_{i1};\cdots;x_{ij})$，分号表示列向量
- 训练，训练集，假设空间，假设，真相（真实），在假设空间中根据（指定了参数的）算法使模型接近真实。算法、参数、数据集都会影响训练结果
- 示例+标记：“样例” $(x_i,y_i)$，标记空间，输出空间
- 分类，回归，二分类，正类，负类。（看输出空间是啥）
- 聚类，簇（可能对应潜在的语义，但我们一般聚类前不知道。聚类的样本通常不具有标记信息），无监督
- 测试，测试样本，测试标记
- 泛化能力：适用于整个样本空间
  - 无论是典型的监督（分类回归）还是典型的无监督（聚类），都希望在测试样本上也生效
  - 假设样本空间中全体样本服从未知$\mathcal D$，独立同分布
# 假设空间
- 归纳学习：广义从样例学习，狭义学得概念（难，研究的少）
- 比如学习好/坏瓜二分类概念
- 死记硬背，机械学习
- 空间中搜索出匹配(fit)的假设
  - 比如把假设写成树，$色=*,根=*,声=*$的一个子节点是$色=青,根=*,声=*$等
  - 搜索策略：上至下/下至上/同时等
- 多个假设都符合：版本空间version space
# 归纳偏好
- “偏好”
  - 在可行的版本空间中选择模型，如喜欢“特殊”，“一般”，看重什么特征等
    - 更广义的：人类专家知识得到的先验、超参、损失项等
    - 例如：认为相似的样本有相似的输出
  - 这里的“看重特征”是归纳偏好的一部分，和纯从样本中进行[[11-feature-selection]]不同
- 奥卡姆剃刀，平滑，简单
- 不同问题当然需要不同偏好
  - 总误差和学习算法无关。没有免费午餐！参考[[1-intro-NFL]]