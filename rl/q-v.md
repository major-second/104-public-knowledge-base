前置[[mdp]]
[参考](https://zhuanlan.zhihu.com/p/109498587)
Q, V共同点：一个节点出发，下面所有节点的收获的期望值
值|V|Q|
-|-|-|
考察“节点”|状态|状态+动作|
助记|VS|QA|
是什么期望|子节点（动作）Q期望|子节点（状态）V期望
备注说明|和策略相关。因为策略决定接下来动作分布|动作本身产生的奖励需要计算

原始方法计算：直接[[dp]]倒推。计算量过大，且需要一直环境等